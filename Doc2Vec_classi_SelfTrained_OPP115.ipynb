{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import scipy.sparse as sps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset # pip3 install scikit-multilearn\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website</th>\n",
       "      <th>alltext</th>\n",
       "      <th>segment ID</th>\n",
       "      <th>Data Retention</th>\n",
       "      <th>Data Security</th>\n",
       "      <th>Do Not Track</th>\n",
       "      <th>First Party Collection/Use</th>\n",
       "      <th>International and Specific Audiences</th>\n",
       "      <th>Introductory/Generic</th>\n",
       "      <th>Policy Change</th>\n",
       "      <th>Practice not covered</th>\n",
       "      <th>Privacy contact information</th>\n",
       "      <th>Third Party Sharing/Collection</th>\n",
       "      <th>User Access, Edit and Deletion</th>\n",
       "      <th>User Choice/Control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1017_sci-news.com</td>\n",
       "      <td>- details of your visits to our site including...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1017_sci-news.com</td>\n",
       "      <td>- if you contact us, we may keep a record of t...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             website                                            alltext  \\\n",
       "0  1017_sci-news.com  - details of your visits to our site including...   \n",
       "1  1017_sci-news.com  - if you contact us, we may keep a record of t...   \n",
       "\n",
       "   segment ID  Data Retention  Data Security  Do Not Track  \\\n",
       "0           3             0.0            0.0           0.0   \n",
       "1           2             1.0            0.0           0.0   \n",
       "\n",
       "   First Party Collection/Use  International and Specific Audiences  \\\n",
       "0                         1.0                                   0.0   \n",
       "1                         0.0                                   0.0   \n",
       "\n",
       "   Introductory/Generic  Policy Change  Practice not covered  \\\n",
       "0                   0.0            0.0                   0.0   \n",
       "1                   0.0            0.0                   0.0   \n",
       "\n",
       "   Privacy contact information  Third Party Sharing/Collection  \\\n",
       "0                          0.0                             0.0   \n",
       "1                          0.0                             0.0   \n",
       "\n",
       "   User Access, Edit and Deletion  User Choice/Control  \n",
       "0                             0.0                  0.0  \n",
       "1                             0.0                  0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_ori = pd.read_csv('/Users/namrata/Documents/PSU/Thesis_research/Cybersecurity_framework/Data/OPP-115/data_to_gitlab/Cleaned_multilabel_dataset.txt',sep='\\t')\n",
    "del Dataset_ori['Other']\n",
    "Dataset_ori.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_ori = Dataset_ori.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_ori['alltext'] = Dataset_ori['alltext'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset_ori.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_questions=[]\n",
    "for i in range(len(Dataset_ori)):\n",
    "    labeled_questions.append(TaggedDocument(Dataset_ori['alltext'].iloc[i].split(), Dataset_ori[Dataset_ori.index == i].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['we', 'use', 'third', 'party', 'advertising', 'companies', 'to', 'serve', 'ads', 'when', 'you', 'visit', 'websites', 'operated', 'by', 'the', 'news', 'post', 'these', 'companies', 'may', 'use', 'information', 'not', 'including', 'your', 'name', 'address', 'email', 'address', 'or', 'telephone', 'number', 'about', 'your', 'visits', 'to', 'this', 'and', 'other', 'web', 'sites', 'in', 'order', 'to', 'provide', 'advertisements', 'about', 'goods', 'and', 'services', 'of', 'interest', 'to', 'you', 'if', 'you', 'would', 'like', 'more', 'information', 'about', 'this', 'practice', 'and', 'to', 'know', 'your', 'choices', 'about', 'not', 'having', 'this', 'information', 'used', 'by', 'these', 'companies', 'visit', 'http', 'www', 'networkadvertising', 'org'], tags=Int64Index([2345], dtype='int64'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_questions[2345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(dm = 0, min_count=1, window=10, size=300,alpha=0.01)\n",
    "model.build_vocab(labeled_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3574"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "for epoch in range(50):\n",
    "    print('Epoch {}'.format(epoch))\n",
    "    model.train(utils.shuffle([x for x in labeled_questions]), total_examples=len(labeled_questions), epochs=1)\n",
    "#     model.alpha -= 0.002\n",
    "#     model.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for epoch in range(50):\n",
    "#     model.train(labeled_questions,epochs=model.iter,total_examples=model.corpus_count)\n",
    "#     print(\"Epoch #{} is complete.\".format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_ori[\"Id\"] = Dataset_ori['website'] + Dataset_ori['segment ID'].astype('str')\n",
    "labels_order = Dataset_ori.columns[3:-1]\n",
    "all_websites = Dataset_ori['website'].unique()\n",
    "web_dict = Counter(all_websites)\n",
    "\n",
    "selection_per_loop = dict()\n",
    "\n",
    "fraction =1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  0\n",
      "Before upsampling:  (2271, 300) (2271, 12) (1303, 300) (1303, 12)\n",
      "After Up-sampling (41472, 300) (41472, 12) (1303, 300) (1303, 12)\n",
      "Average resulting F-1 Score in fold 0.1862504963477536\n",
      "Fold:  1\n",
      "Before upsampling:  (2350, 300) (2350, 12) (1224, 300) (1224, 12)\n",
      "After Up-sampling (46080, 300) (46080, 12) (1224, 300) (1224, 12)\n",
      "Average resulting F-1 Score in fold 0.14891595017463197\n",
      "Fold:  2\n",
      "Before upsampling:  (2413, 300) (2413, 12) (1161, 300) (1161, 12)\n",
      "After Up-sampling (51408, 300) (51408, 12) (1161, 300) (1161, 12)\n",
      "Average resulting F-1 Score in fold 0.19945457326258506\n",
      "Fold:  3\n",
      "Before upsampling:  (2237, 300) (2237, 12) (1337, 300) (1337, 12)\n",
      "After Up-sampling (40560, 300) (40560, 12) (1337, 300) (1337, 12)\n",
      "Average resulting F-1 Score in fold 0.1725251461674662\n",
      "Fold:  4\n",
      "Before upsampling:  (2425, 300) (2425, 12) (1149, 300) (1149, 12)\n",
      "After Up-sampling (50301, 300) (50301, 12) (1149, 300) (1149, 12)\n",
      "Average resulting F-1 Score in fold 0.1415503283490035\n",
      "Fold:  5\n",
      "Before upsampling:  (2349, 300) (2349, 12) (1225, 300) (1225, 12)\n",
      "After Up-sampling (48861, 300) (48861, 12) (1225, 300) (1225, 12)\n",
      "Average resulting F-1 Score in fold 0.19959507045473976\n",
      "Fold:  6\n",
      "Before upsampling:  (2072, 300) (2072, 12) (1502, 300) (1502, 12)\n",
      "After Up-sampling (39026, 300) (39026, 12) (1502, 300) (1502, 12)\n",
      "Average resulting F-1 Score in fold 0.16266975218488788\n",
      "Fold:  7\n",
      "Before upsampling:  (2505, 300) (2505, 12) (1069, 300) (1069, 12)\n",
      "After Up-sampling (50544, 300) (50544, 12) (1069, 300) (1069, 12)\n",
      "Average resulting F-1 Score in fold 0.1851903821053175\n",
      "Fold:  8\n",
      "Before upsampling:  (2427, 300) (2427, 12) (1147, 300) (1147, 12)\n",
      "After Up-sampling (49219, 300) (49219, 12) (1147, 300) (1147, 12)\n",
      "Average resulting F-1 Score in fold 0.1640997054499692\n",
      "Fold:  9\n",
      "Before upsampling:  (2160, 300) (2160, 12) (1414, 300) (1414, 12)\n",
      "After Up-sampling (42420, 300) (42420, 12) (1414, 300) (1414, 12)\n",
      "Average resulting F-1 Score in fold 0.1483488975834609\n"
     ]
    }
   ],
   "source": [
    "folds = 10\n",
    "\n",
    "lp = LabelPowerset()\n",
    "ros = RandomOverSampler(random_state=420)\n",
    "\n",
    "\n",
    "for count in range(folds):\n",
    "# count=0\n",
    "    print('Fold: ',count)\n",
    "    itemminValue = min(web_dict.items(), key=lambda x: x[1])\n",
    "\n",
    "    min_val = itemminValue[1]\n",
    "    minimum_webs = list()\n",
    "    # print(min_val)\n",
    "    for key, value in web_dict.items():\n",
    "        if value == min_val:\n",
    "            minimum_webs.append(key)\n",
    "    random.shuffle(minimum_webs)\n",
    "\n",
    "    selected_test_webs = minimum_webs[0:40]\n",
    "\n",
    "    while len(selected_test_webs)<40:\n",
    "        min_val+=1\n",
    "        minimum_webs = list()\n",
    "        for key, value in web_dict.items():\n",
    "            if value == min_val:\n",
    "                minimum_webs.append(key)\n",
    "        random.shuffle(minimum_webs)\n",
    "        selected_test_webs = list(set(selected_test_webs)|set(minimum_webs[0:40-len(selected_test_webs)]))\n",
    "        # print('final len of test sites',len(selected_test_webs))\n",
    "\n",
    "    for tw in selected_test_webs:\n",
    "        web_dict[tw] += 1\n",
    "    selection_per_loop[count] = selected_test_webs\n",
    "\n",
    "    train_df = Dataset_ori[~Dataset_ori['website'].isin(selected_test_webs)]\n",
    "    test_df = Dataset_ori[Dataset_ori['website'].isin(selected_test_webs)]\n",
    "\n",
    "    train_df=train_df.sample(frac=fraction)\n",
    "    test_df=test_df.sample(frac=fraction)\n",
    "\n",
    "    train_text_ori = train_df['alltext'].tolist()\n",
    "    # train_text_ori = [' '.join(t.split()) for t in train_text_ori]\n",
    "    # train_text_ori = np.array(train_text_ori, dtype=object)[:, np.newaxis]\n",
    "    train_label_ori = train_df.values[:,3:-1].astype(int)\n",
    "\n",
    "    test_text = test_df['alltext'].tolist()\n",
    "    # test_text = [' '.join(t.split()) for t in test_text]\n",
    "    # test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
    "    test_label = test_df.values[:,3:-1].astype(int)\n",
    "    \n",
    "\n",
    "    X1 = []\n",
    "    for i in range(len(train_text_ori)):\n",
    "        fullText = clean_text(train_text_ori[i])\n",
    "        vec_inp = fullText.strip().split()\n",
    "        vector = np.array([x for x in model.infer_vector(vec_inp,steps=100,alpha=0.01)])\n",
    "        X1.append(vector)\n",
    "    train_X = np.array(X1)\n",
    "\n",
    "    X2 = []\n",
    "    for i in range(len(test_text)):\n",
    "        fullText = clean_text(test_text[i])\n",
    "        vec_inp = fullText.strip().split()\n",
    "        vector = np.array([x for x in model.infer_vector(vec_inp,steps=100,alpha=0.01)])\n",
    "        X2.append(vector)\n",
    "    test_X = np.array(X2)\n",
    "\n",
    "    # print(test_X.shape)\n",
    "\n",
    "    train_X_norm = min_max_scaler.fit_transform(train_X)\n",
    "    test_X_norm = min_max_scaler.fit_transform(test_X)\n",
    "\n",
    "    print('Before upsampling: ',train_X_norm.shape,train_label_ori.shape,test_X_norm.shape,test_label.shape)\n",
    "\n",
    "    yt = lp.transform(train_label_ori)\n",
    "    train_X_norm_up, y_resampled = ros.fit_sample(train_X_norm, yt)\n",
    "    # train_text = train_text_ori\n",
    "    # train_label = train_label_ori\n",
    "    train_label = lp.inverse_transform(y_resampled).toarray()\n",
    "\n",
    "    print('After Up-sampling',train_X_norm_up.shape,train_label.shape,test_X_norm.shape,test_label.shape)\n",
    "    \n",
    "    \n",
    "    NB_pipeline = Pipeline([\n",
    "                    #('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                    ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                        fit_prior=True, class_prior=None))),\n",
    "                ])        \n",
    "\n",
    "    all_pred_res = []\n",
    "    for category in range(train_label.shape[1]):\n",
    "        NB_pipeline.fit(train_X_norm_up, train_label[:,category].reshape((train_label.shape[0], 1)))\n",
    "        preds = NB_pipeline.predict(test_X_norm)\n",
    "        all_pred_res.append(preds)\n",
    "\n",
    "    # print(len(all_pred_res))\n",
    "    pred_binary = np.asarray(all_pred_res).T\n",
    "\n",
    "    # print(pred_binary.shape)\n",
    "\n",
    "    result_scores = pd.DataFrame()\n",
    "    avg_f1 = []\n",
    "    for category in range(train_label.shape[1]):\n",
    "        label_name = labels_order[category]\n",
    "\n",
    "    #     lr_precision, lr_recall, _ = precision_recall_curve(test_label[:,category].astype('float'), pre_save_preds[:,category])\n",
    "        lr_f1 = f1_score(test_label[:,category].astype(int), pred_binary[:,category])#, auc(lr_recall, lr_precision)\n",
    "\n",
    "        if sum(test_label[:,category])==0 and sum(pred_binary[:,category])==0:\n",
    "            tp=0\n",
    "            fp=0\n",
    "            tn=len(pred_binary[:,category])\n",
    "            fn=0\n",
    "        else:\n",
    "            tn, fp, fn, tp = confusion_matrix(test_label[:,category].astype(int), pred_binary[:,category]).ravel()\n",
    "\n",
    "        if tp+fp==0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = float(tp)/float(tp+fp)\n",
    "\n",
    "        if tp+fn==0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = float(tp)/float(tp+fn)\n",
    "\n",
    "        avg_f1.append(lr_f1)\n",
    "        df = pd.DataFrame([{'Fold':count,'category':label_name,'tp':tp,'fp':fp,'tn':tn,'fn':fn,'recall':recall,'precision':precision,'f1':lr_f1}])\n",
    "\n",
    "        result_scores = result_scores.append(df)\n",
    "#     print(result_scores)\n",
    "    print('Average resulting F-1 Score in fold',np.mean(avg_f1))\n",
    "#     if count==0:\n",
    "#         result_scores.to_csv('/Users/namrata/Documents/PSU/Thesis_research/Cybersecurity_framework/Exp_res/Doc2Vec_Classi/OPP_115/Doc2Vec_OPP_res_selftrained_upsampled.csv',header=True,mode='a',sep='\\t')\n",
    "#     else:\n",
    "#         result_scores.to_csv('/Users/namrata/Documents/PSU/Thesis_research/Cybersecurity_framework/Exp_res/Doc2Vec_Classi/OPP_115/Doc2Vec_OPP_res_selftrained_upsampled.csv',header=False,mode='a',sep='\\t')\n",
    "\n",
    "    count+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48590, 300)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
